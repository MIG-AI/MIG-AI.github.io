<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="./common.css">
    <style>
        .newlist {
            margin: 0;
            padding: 0;
        }

        .newlist li {
            list-style: none;
            overflow: hidden;
            padding: 20px 10px;
        }

        .newlist li+li {
            margin-top: 20px;
            border-top: 2px solid rgba(64, 64, 64, 0.8);
        }

        .date {
            width: 60px;
            text-align: center;
            float: left;
        }

        .date span {
            padding: 10px 0;
            display: inline-block;
            width: 100%;
            background: #dadada;
        }

        .month {
            background: rgba(64, 64, 64, 0.8);
            color: #ffffff;
            font-weight: bold;
            padding: 5px 0;
        }

        .new-wrap {
            margin-left: 100px;
        }

        .new-wrap .title {
            font-weight: bold;
            font-size: 18px;
            padding: 10px 0;
        }

        .new-wrap .more {
            float: right;
            margin-top: 20px;
            background: #c0c0c0;
            padding: 8px;
            border-radius: 5px;
            color: #fff;
            cursor: pointer;
        }

        .new-wrap .more a {
            text-decoration: none;
            color: #fff;
        }

        @media screen and (max-width:649px) {
            .date {
                margin: 0 20px 0 0;
            }

            .new-wrap {
                margin-left: 0;
            }
        }
    </style>
    <title>News</title>
</head>

<body>
    <div class="container">
        <div class="concent-wrap">
            <header class="header">
                <div class="logo"></div>
                <nav class="nav">
                    <ul>
                        <li><a href="./index.html">Home</a></li>
                        <li><a href="./people.html">People</a></li>
                        <li><a href="./publications.html">Publications</a></li>
                        <li class="active"><a href="./news.html">News</a></li>
                        <li><a href="./join.html">Join</a></li>
                        <li><a href="./cn/news.html">简体中文</a></li>
                    </ul>
                </nav>
                <div class="drawer-handle">
                    <div class="drawer-mask"></div>
                    <i class="drawer-handle-icon"></i>
                </div>
            </header>
            <div class="content">
                <ul class="newlist">

					<li>
                        <div class="date">
                            <span>2023</span>
                            <div class="month">
                                Sept. 22
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Two papers from MIG were accepted in NeurIPS 2023.
                            </div>
							<div class="new-content">
                                Two papers from MIG: 
                                <strong> Conservative Offline Policy Adaptation in Multi-Agent Games</strong>, 
                                <strong> Unsupervised Behavior Extraction via Random Intent Priors</strong>, 
                                have been accepted by NeurIPS 2023.

                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div class="date">
                            <span>2023</span>
                            <div class="month">
                                Sept. 22
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Paper from MIG was accepted in TMLR.
                            </div>
							<div class="new-content">
                                Paper from MIG: 
                                <strong> A Survey on Transformers in Reinforcement Learning</strong>, 
                                has been accepted by TMLR.

                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div class="date">
                            <span>2023</span>
                            <div class="month">
                                Sept. 22
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Paper from MIG was accepted in IROS 2023.
                            </div>
							<div class="new-content">
                                Papers from MIG: 
                                <strong> Learning to Solve Tasks with Exploring Prior Behaviours</strong>, 
                                has been accepted by IROS 2023.

                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

					<li>
                        <div class="date">
                            <span>2023</span>
                            <div class="month">
                                Apr. 25
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Three papers from MIG were accepted in ICML 2023.
                            </div>
							<div class="new-content">
                                Three papers from MIG: 
                                <strong> Offline Meta Reinforcement Learning with In-Distribution Online Adaptation</strong>, 
                                <strong> Symmetry-Aware Robot Design with Structured Subgroups Inbox</strong>, 
                                <strong> What is Essential for Unseen Goal Generalization of Offline Goal-conditioned RL</strong>,
                                have been accepted by ICML 2023.

                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

					<li>
                        <div class="date">
                            <span>2023</span>
                            <div class="month">
                                Jan. 22
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Paper from MIG was accepted in ICLR 2023.
                            </div>
							<div class="new-content">
                                Paper from MIG: <strong> The Provable Benefit of Unsupervised Data Sharing for Offline Reinforcement Learning</strong>,
                                has been accepted by ICLR 2023.

                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

					<li>
                        <div class="date">
                            <span>2022</span>
                            <div class="month">
                                Nov. 26
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Paper from MIG was accepted in AAAI 2023.
                            </div>
							<div class="new-content">
                                Paper from MIG: <strong> Flow to Control: Offline Reinforcement Learning with Lossless Primitive Discovery </strong>, 
                                has been accepted by AAAI 2023.

                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div class="date">
                            <span>2022</span>
                            <div class="month">
                                Sept. 15
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Six papers from MIG were accepted in NeurIPS 2022.
                            </div>
							<div class="new-content">
                                Six papers from MIG: <strong> Non-Linear Coordination Graphs </strong>, 
                                <strong> Safe Opponent-Exploitation Subgame Refinement </strong>, 
                                <strong> RORL: Robust Offline Reinforcement Learning via Conservative Smoothing </strong>, 
                                <strong> Low-Rank Modular Reinforcement Learning via Muscle Synergy </strong>,
                                <strong> CUP: Critic-Guided Policy Reuse </strong>,
                                <strong> Latent-Variable Advantage-Weighted Policy Optimization for Offline Reinforcement Learning </strong>,
                                have been accepted by NeurIPS 2022.

                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div class="date">
                            <span>2022</span>
                            <div class="month">
                                May. 15
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Three papers from MIG were accepted in ICML 2022.
                            </div>
							<div class="new-content">
                                Three papers from MIG: <strong> On the Role of Discount Factor in Offline Reinforcement Learning
                                </strong>,<strong> Self-Organized Polynomial-Time Coordination Graphs </strong>, 
                                <strong> Individual Reward Assisted Multi-Agent Reinforcement Learning </strong>, have been accepted by International Conference on Machine Learning (ICML) 2022.

                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div class="date">
                            <span>2022</span>
                            <div class="month">
                                Jan. 21
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Four papers from MIG were accepted in ICLR 2022.
                            </div>
							<div class="new-content">
                                Four Papers from MIG: <strong> Context-Aware Sparse Deep Coordination Graphs </strong>, <strong> Active Hierarchical Exploration with Stable Subgoal Representation Learning
                                </strong>, <strong>Rethinking Goal-Conditioned Supervised Learning and Its Connection to Offline RL
                                </strong>, <strong>Offline Reinforcement Learning with Value-based Episodic Memory</strong>
                                have been accepted by International Conference on  earning
                                Representations (ICLR) 2022.

                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

                    <li>


                    <li>
                        <div class="date">
                            <span>2021</span>
                            <div class="month">
                                Dec. 2
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Paper from MIG was accepted in AAAI 2022.
                            </div>
							<div class="new-content">
                                Paper from MIG: <strong> Multi-Agent Incentive Communication via Decentralized Teammate Modeling </strong>, 
                                has been accepted for presentation at the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22). This year AAAI received a record 9,251
                                submissions, of which 9,020 were reviewed. Based on a thorough and rigorous review process, AAAI has accepted 1,349 papers. This
                                yields an overall acceptance rate of 15%.

                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div class="date">
                            <span>2021</span>
                            <div class="month">
                                Oct. 14
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Jianhao Wang and Lulu Zheng were awarded with National Scholarship (top 1%) at Tsinghua University.
                            </div>
							<div class="new-content">
                                Jianhao Wang, a PhD candidate from MIG group, was awarded with National Scholarship (top 1%) at Tsinghua University, due to his impressing scientific research achievements.
                                Lulu Zheng, a master candidate from MIG group, was awarded with National Scholarship, too.
                                National Scholarship is the most important award in Tsinghua University and this year only 5 graduate students obtained this scholarship in Institute for Interdisciplinary Information Sciences (IIIS).
                                Till now, there are 5 students in total from MIG group  who has won National Scholarship.

                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div class="date">
                            <span>2021</span>
                            <div class="month">
                                Sep. 29
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                             Six papers from MIG were accepted in NeurIPS 2021.
                            </div>
							<div class="new-content">
                                Six papers from MIG: <strong> Celebrating Diversity in Shared Multi-Agent Reinforcement Learning </strong>,
                                <strong> Offline Reinforcement Learning with Reverse Model-based Imagination</strong>, <strong> On the Estimation Bias in Double Q-Learning </strong>,
                                 <strong>Episodic Multi-agent Reinforcement Learning with Curiosity-driven Exploration</strong>, <strong>Towards Understanding Cooperative Multi-Agent Q-Learning with Value Factorization</strong>,
                                <strong>Model-Based Reinforcement Learning via Imagination with Derived Memory</strong>, were accepted at NeurIPS 2021. The topics of these papers are diverse, including multi-agent RL, offline RL, and Model-based RL.

                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div class="date">
                            <span>2021</span>
                            <div class="month">
                                June. 28
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                             Three students graduated from MIG in June, 2021, and Guangxiang Zhu has won the award for Excellent Doctoral Dissertation of Tsinghua University, 2021
                            </div>
							<div class="new-content">
                                Guangxiang Zhu, Terry Liu, and Tonghan Wang graduated from MIG in June, 2021. Guangxiang, as the first student to obtain a PhD's degree in MIG,
                                has won the award for Excellent Doctoral Dissertation of Tsinghua University, 2021, creating a milestone for MIG.
                                Besides, Terry and Tonghan are the first two students to obtain a Master of Computer Sciences in MIG.


                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div class="date">
                            <span>2021</span>
                            <div class="month">
                                May. 8
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                             Two papers from MIG were accepted in ICML 2021.
                            </div>
							<div class="new-content">
                                Two papers from MIG, <strong> MetaCURE: Meta Reinforcement Learning with Empowerment-Driven Exploration </strong>,
                                and <strong> Generalizable Episodic Memory for Deep Reinforcement Learning </strong> were accepted at ICML 2021,
                               There were 5513 submissions to ICML this year, of which the program committee accepted 1184 for presentation at the conference,
                                including 166 long presentations and 1018 short presentations.
                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div class="date">
                            <span>2021</span>
                            <div class="month">
                                April. 30
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                             Paper from MIG was accepted in IJCAI 2021.
                            </div>
							<div class="new-content">
                                The paper from MIG collaborated with NetEase, <strong> Reward-Constrained Behavior Cloning </strong>, was accepted for presentation at IJCAI-21
                                (the 30th International Joint Conference on Artificial Intelligence).
                                Out of the 4204 full-paper submissions, 587 papers are finally accepted, at a 13.9% acceptance rate
                                (19.3% out of the 3033 papers which passed the summary-reject review phase and received full reviews).
                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>


                    <li>
                        <div class="date">
                            <span>2021</span>
                            <div class="month">
                                Jan. 14
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                             Four papers from MIG were accepted in ICLR 2021.
                            </div>
							<div class="new-content">
                                 Four papers from MIG were accepted by International Conference on  earning
                                Representations (ICLR) 2021. Tonghan Wang, Jianhao Wang and Beining Han focused Multi-Agent Reinforcement Learning (MARL). Our group's paper:
                                <strong>RODE: Learning Roles to Decompose Multi-Agent Tasks.</strong> and <strong> Off-Policy Multi-Agent Decomposed Policy Gradients.</strong> are accepted.
                                Another accepted paper <strong> QPLEX: Duplex Dueling Multi-Agent Q-Learning</strong> encodes the IGM principle into the neural network architecture and thus enables efficient value function learning.
                                Siyuan Li and Lulu Zheng focused on hierarchical Reinforcement Learning and used slow features to define subgoals in their paper <strong>Learning Subgoal Representations
                                with Slow Dynamics </strong>, which was also accepted in ICLR 2021.
                            </div>

                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>
                    <li>
                        <div class="date">
                            <span>2020</span>
                            <div class="month">
                                Oct. 22
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Tonghan Wang was awarded with National Scholarship (top 1%) at Tsinghua University, 2020.
                            </div>
							<div class="new-content">
                                Tonghan Wang, a master candidate from MIG group, was awarded with National Scholarship (top 1%) at Tsinghua University, due to his impressing scientific research achievements.
                                National Scholarship is the most important award in Tsinghua University and only 4 graduate students can obtain this scholarship in Institute for Interdisciplinary Information Sciences (IIIS) every year.
                                Besides, Tonghan is the third student in MIG group to win National Scholarship.
                                </div>
                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>
					<li>
                        <div class="date">
                            <span>2020</span>
                            <div class="month">
                                Sep. 15
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Paper: "Bridging Imagination and Reality for Model-Based Deep Reinforcement Learning" from MIG was accepted in NeurIPS 2020
                            </div>
							<div class="new-content">
                                Sample efficiency has been one of the major challenges for deep reinforcement learning. 
								Recently, model-based reinforcement learning has been proposed to address this challenge by performing planning on imaginary trajectories with a learned world model. 
								However, world model learning may suffer from overfitting to training trajectories, and thus model-based value estimation and policy search will be prone to be sucked in an inferior local policy. 
								In this paper, we propose a novel model-based reinforcement learning algorithm, called BrIdging Reality and Dream (BIRD). 
								It maximizes the mutual information between imaginary and real trajectories so that the policy improvement learned from imaginary trajectories can be easily generalized to real trajectories. 
								We demonstrate that our approach improves sample efficiency of model-based planning, and achieves state-of-the-art performance on challenging visual control benchmarks.
                                </div>
                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>
                    <li>
                        <div class="date">
                            <span>2020</span>
                            <div class="month">
                                June 15
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Paper: "ROMA: Multi-Agent Reinforcement Learning with Emergent Roles" from MIG was accepted in ICML 2020
                            </div>
                            <div class="new-content">
                                ROMA learns sub-task specialization in cooperative agent teams by proposing a role-oriented learning framework. 
                                In this framework, roles are emergent, and agents with similar roles tend to share their learning to be specialized on certain 
                                sub-tasks. ROMA can learn specialized, dynamic, versatile, and identifiable roles, and push forward the state of the art on the 
                                StarCraft II micromanagement benchmark.
                                </div>
                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>
                    <li>
                        <div class="date">
                            <span>2020</span>
                            <div class="month">
                                Jan.9
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Three papers from MIG were accepted in ICLR 2020
                            </div>
                            <div class="new-content">
                                Three papers from MIG were accepted by International Conference on  earning
                                Representations (ICLR) 2020. Tonghan Wang and Jianhao Wang focused on exploration and
                                communication problems in Multi-Agent Reinforcement Learning (MARL). Both of their
                                papers: <strong>Influence-Based Multi-Agent Exploration</strong> and <strong>Learning
                                    Nearly Decomposable Value-Functions via Communication Minimization</strong> were
                                accepted.
                                Influence-Based
                                Multi-Agent Exploration was accepted as spotlight. Guangxiang Zhu focused on combining
                                episodic control with reinforcement learning and his paper <strong>Episodic
                                    Reinforcement
                                    Learning with Associative Memory</strong> was also accepted.</div>
                            <div class="more">
                                <a href="https://iiis.tsinghua.edu.cn/show-8391-1.html" target="_blank">Read more...</a>
                            </div>
                        </div>
                    </li>
                    <li>
                        <div class="date">
                            <span>2019</span>
                            <div class="month">
                                Nov.11
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Paper: "Object-Oriented Dynamics Learning through Multi-Level Abstraction" from MIG was accepted in AAAI Conference on Artificial Intelligence (AAAI), 2020
                            </div>
                            <div class="new-content">
                                This paper presents a novel self-supervised object-oriented framework to enable efficient object-based dynamics
                                learning and planning, which employs a three-level learning architecture from motion detection, to dynamic instance
                                 segmentation, and to dynamics learning. This framework can learn model from few interactions with environments and
                                 enable an agent to directly plan in unseen environments without retraining. In addition, it learns semantically and
                                 visually interpretable representations.
                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div class="date">
                            <span>2019</span>
                            <div class="month">
                                Oct.15
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                 GuangXiang Zhu and Siyuan Li both were awarded with National Scholarship (top 1%) at Tsinghua University
                            </div>
                            <div class="new-content">
                                GuangXiang Zhu and Siyuan Li, two PhD candidates from MIG group, were both awarded with National Scholarship (top 1%) at Tsinghua University, for their impressing achievements in scientific research.
                                National Scholarship is the most important award in Tsinghua University and only 4 graduate students can obtain this scholarship in Institute for Interdisciplinary Information Sciences (IIIS) every year.
                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div class="date">
                            <span>2019</span>
                            <div class="month">
                                Sep.4
                            </div>
                        </div>
                        <div class="new-wrap">
                            <div class="title">
                                Paper: "Hierarchical Reinforcement Learning with Advantage-Based Auxiliary Rewards" was accepted by Conference and Workshop on Neural Information Processing Systems (NeurIPS), 2019
                            </div>
                            <div class="new-content">
                                This paper aims to adapt low-level skills to downstream tasks while maintaining the generality of reward design. Siyuan Li and Rui Wang proposed an HRL framework which 
                                sets auxiliary rewards for low-level skill training based on the advantage function of the high-level policy. This auxiliary reward enables efficient, simultaneous 
                                learning of the high-level policy and low-level skills without using task-specific knowledge. In addition, they also theoretically prove that optimizing low-level 
                                skills with this auxiliary reward will increase the task return for the joint policy.
                            <div class="more">
                                <a href="./publications.html">Read more...</a>
                            </div>
                        </div>
                    </li>
                </ul>
            </div>
        </div>
    </div>
</body>

<script>
    var drawer = document.querySelector(".drawer-handle");
    var nav = document.querySelector(".nav");
    drawer.addEventListener("click", function (e) {
        var e = e || window.event, target = e.target || e.srcElement; //    IE
        if (target.className === "drawer-handle") {
            target.className = "drawer-handle drawer-open";
            nav.className = "nav nav-open";
            document.body.style.position = "fixed";
        } else {
            target.className = "drawer-handle";
            nav.className = "nav";
            document.body.style.position = "relative";
        }
    })
</script>

</html>